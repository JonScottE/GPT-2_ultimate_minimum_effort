{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a4e76f-a4c1-41ed-a457-8766c789922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\16177\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\16177\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.6.0 tokenizers-0.12.1 transformers-4.19.2\n",
      "Requirement already satisfied: torch in c:\\users\\16177\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\16177\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "# using GPT-2 to generate text\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "# Initialization\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925db6e1-b798-496c-a3a3-7e24ba08fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizer and model from pretrained GPT2 model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efdd57cf-edfc-4136-a669-23fb66f7a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Hiring Manager, I am writing to apply for the data scientist position at your company. My excellent analytical and problem-solving skills, education, and amount of real world experience, make me perfect for this position.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to define sequence here\n",
    "sequence = ('Dear Hiring Manager, I am writing to apply for the data scientist position at your company. My excellent analytical and problem-solving skills, education, and amount of real world experience, make me perfect for this position.')\n",
    "sequence \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ddcee97-6c20-45ff-923b-358223e5a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Dear Hiring Manager, I am writing to apply for the data scientist position at your company. My excellent analytical and problem-solving skills, education, and amount of real world experience, make me perfect for this position. However, if you cannot find anything good to say in your answers, please do not hesitate to contact me.\\n\\nYour position is a good opportunity for your colleagues to make an informed assessment of your abilities and experience, so I sincerely apologize. I've also given you a chance to apply for a position outside of the company. However, I'm willing to give other advice to my current employer if there are problems or situations that need to be addressed.\\n\\nI'd love this opportunity, too!\\n\\nSincerely,\\n\\nSteve Bould\\n\\nSenior Executive\\n\\nMicrosoft Engineering Solutions\\n\\n814-782-3141\\n\\nsteve@microsoft.com\\n\\nLinkedIn\\n\\n[Back to top]\\n\\nProduct Research Manager - HR | Software Development\\n\\n[Back to top]\\n\\nProduct Sales\\n\\nProduct Sales Division\\n\\n[Back to top]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
    "\n",
    "outputs = model.generate(inputs, max_length=425, do_sample=True, temperature=1) # 1 - 5 temperature, 5 more random\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b0b0e-b87c-428a-89aa-4d6b65c1f0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c00e5-71c0-4fc6-b1b4-47aba5e4e39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a076a3-ebb0-4746-b9cd-1c90ebf379ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e893c-93a7-4fda-b472-580a7e204286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81624068-8deb-4fa4-98bb-836396409bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
